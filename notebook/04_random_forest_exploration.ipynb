{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c48bafd1-ff86-4c67-b851-63b74ad7c289",
   "metadata": {},
   "source": [
    "## Random Forest Exploration\n",
    "This notebook evaluates whether a non-linear ensemble (Random Forest) provides\n",
    "meaningful improvements over logistic regression, given hardware and compute constrains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03928e75-b88f-4521-be41-b744687d7035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the downloaded data from Kaggle\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15361ca4-822c-4775-8bfb-afb390cb7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"Class\", axis=1)   # assuming 'Class' is the label\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# Train–test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=50, stratify=y\n",
    ")\n",
    "\n",
    "#Fit scaler on training data only\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f51c83-39df-401a-a1d3-7e2bfd14e814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaishnavi\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\Vaishnavi\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"C:\\Users\\Vaishnavi\\anaconda3\\Lib\\subprocess.py\", line 554, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vaishnavi\\anaconda3\\Lib\\subprocess.py\", line 1039, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vaishnavi\\anaconda3\\Lib\\subprocess.py\", line 1554, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "# Using SMOTE for class imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=50, k_neighbors=5)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af2be6f-2423-4f88-8e0d-346dc2a0fdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199364\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "X_train_smote_df = pd.DataFrame(X_train_smote, columns=X_train.columns)\n",
    "y_train_smote_sr = pd.Series(y_train_smote, name=\"target\")\n",
    "n_original = len(X_train_scaled)\n",
    "print(n_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b97ce27-6d53-46a0-8c8e-77c0486cea5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_smote_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9f65c6-86ce-44af-b608-49da16588eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>is_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199364</th>\n",
       "      <td>1.413858</td>\n",
       "      <td>0.513670</td>\n",
       "      <td>-0.191584</td>\n",
       "      <td>-0.692890</td>\n",
       "      <td>-0.430233</td>\n",
       "      <td>0.057651</td>\n",
       "      <td>-0.307472</td>\n",
       "      <td>0.091250</td>\n",
       "      <td>-0.034340</td>\n",
       "      <td>0.027063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179966</td>\n",
       "      <td>0.422524</td>\n",
       "      <td>0.491732</td>\n",
       "      <td>0.791796</td>\n",
       "      <td>-0.599166</td>\n",
       "      <td>-0.395737</td>\n",
       "      <td>0.050808</td>\n",
       "      <td>0.133889</td>\n",
       "      <td>0.050697</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199365</th>\n",
       "      <td>-0.777657</td>\n",
       "      <td>-2.638496</td>\n",
       "      <td>-0.143050</td>\n",
       "      <td>-2.571326</td>\n",
       "      <td>3.740714</td>\n",
       "      <td>-5.433100</td>\n",
       "      <td>2.891171</td>\n",
       "      <td>1.319879</td>\n",
       "      <td>0.013499</td>\n",
       "      <td>-2.548130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219142</td>\n",
       "      <td>1.712661</td>\n",
       "      <td>-1.774093</td>\n",
       "      <td>-0.082667</td>\n",
       "      <td>-0.652637</td>\n",
       "      <td>0.890843</td>\n",
       "      <td>3.840468</td>\n",
       "      <td>-3.278482</td>\n",
       "      <td>5.269484</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199366</th>\n",
       "      <td>1.547622</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.810322</td>\n",
       "      <td>-3.310242</td>\n",
       "      <td>1.091240</td>\n",
       "      <td>0.304907</td>\n",
       "      <td>-0.992447</td>\n",
       "      <td>-1.147247</td>\n",
       "      <td>0.231530</td>\n",
       "      <td>-1.053749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506016</td>\n",
       "      <td>0.048077</td>\n",
       "      <td>-0.204995</td>\n",
       "      <td>-0.090242</td>\n",
       "      <td>0.900268</td>\n",
       "      <td>1.422340</td>\n",
       "      <td>0.945673</td>\n",
       "      <td>0.518235</td>\n",
       "      <td>-0.342176</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199367</th>\n",
       "      <td>-0.371902</td>\n",
       "      <td>0.030242</td>\n",
       "      <td>0.838018</td>\n",
       "      <td>-0.652070</td>\n",
       "      <td>1.421308</td>\n",
       "      <td>1.258755</td>\n",
       "      <td>-0.493169</td>\n",
       "      <td>0.368652</td>\n",
       "      <td>0.030844</td>\n",
       "      <td>-0.359262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.443953</td>\n",
       "      <td>-0.956630</td>\n",
       "      <td>-0.371829</td>\n",
       "      <td>-1.521698</td>\n",
       "      <td>0.748432</td>\n",
       "      <td>-0.412022</td>\n",
       "      <td>0.275331</td>\n",
       "      <td>0.321380</td>\n",
       "      <td>-0.341504</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199368</th>\n",
       "      <td>1.280015</td>\n",
       "      <td>-0.500190</td>\n",
       "      <td>3.091246</td>\n",
       "      <td>-5.385275</td>\n",
       "      <td>5.108693</td>\n",
       "      <td>0.125166</td>\n",
       "      <td>-1.553427</td>\n",
       "      <td>-2.454151</td>\n",
       "      <td>1.463718</td>\n",
       "      <td>-4.064389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702901</td>\n",
       "      <td>-0.675063</td>\n",
       "      <td>0.032601</td>\n",
       "      <td>-1.892505</td>\n",
       "      <td>0.112759</td>\n",
       "      <td>1.117347</td>\n",
       "      <td>1.293620</td>\n",
       "      <td>0.399456</td>\n",
       "      <td>-0.342403</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398035</th>\n",
       "      <td>-0.752255</td>\n",
       "      <td>0.304369</td>\n",
       "      <td>0.558933</td>\n",
       "      <td>-0.008388</td>\n",
       "      <td>1.543894</td>\n",
       "      <td>0.334196</td>\n",
       "      <td>-0.201913</td>\n",
       "      <td>0.100440</td>\n",
       "      <td>0.184628</td>\n",
       "      <td>-0.702244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>-0.068580</td>\n",
       "      <td>-0.129247</td>\n",
       "      <td>-0.291959</td>\n",
       "      <td>0.617870</td>\n",
       "      <td>-0.027813</td>\n",
       "      <td>-0.023543</td>\n",
       "      <td>0.133395</td>\n",
       "      <td>-0.344205</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398036</th>\n",
       "      <td>-0.558355</td>\n",
       "      <td>-1.302583</td>\n",
       "      <td>0.386965</td>\n",
       "      <td>-2.476653</td>\n",
       "      <td>2.749544</td>\n",
       "      <td>-1.787077</td>\n",
       "      <td>-0.932275</td>\n",
       "      <td>-2.537207</td>\n",
       "      <td>0.712280</td>\n",
       "      <td>-1.964642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974433</td>\n",
       "      <td>0.110299</td>\n",
       "      <td>1.531079</td>\n",
       "      <td>0.225032</td>\n",
       "      <td>-0.821167</td>\n",
       "      <td>-0.671386</td>\n",
       "      <td>1.890358</td>\n",
       "      <td>0.522632</td>\n",
       "      <td>1.045738</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398037</th>\n",
       "      <td>-0.719288</td>\n",
       "      <td>-1.178003</td>\n",
       "      <td>-2.011858</td>\n",
       "      <td>-2.353662</td>\n",
       "      <td>2.244191</td>\n",
       "      <td>-2.008679</td>\n",
       "      <td>-0.164926</td>\n",
       "      <td>-0.698783</td>\n",
       "      <td>0.273642</td>\n",
       "      <td>-0.725882</td>\n",
       "      <td>...</td>\n",
       "      <td>1.665281</td>\n",
       "      <td>-0.963772</td>\n",
       "      <td>-2.357683</td>\n",
       "      <td>-0.116647</td>\n",
       "      <td>0.440763</td>\n",
       "      <td>1.101008</td>\n",
       "      <td>0.737277</td>\n",
       "      <td>1.597718</td>\n",
       "      <td>5.089672</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398038</th>\n",
       "      <td>1.116084</td>\n",
       "      <td>0.617068</td>\n",
       "      <td>1.647715</td>\n",
       "      <td>-3.609284</td>\n",
       "      <td>3.839692</td>\n",
       "      <td>0.920516</td>\n",
       "      <td>-1.180513</td>\n",
       "      <td>-0.822104</td>\n",
       "      <td>0.128453</td>\n",
       "      <td>-2.501158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322107</td>\n",
       "      <td>-0.580361</td>\n",
       "      <td>-0.230338</td>\n",
       "      <td>-0.064846</td>\n",
       "      <td>1.169091</td>\n",
       "      <td>0.406801</td>\n",
       "      <td>1.213158</td>\n",
       "      <td>0.869423</td>\n",
       "      <td>-0.339422</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398039</th>\n",
       "      <td>-0.128231</td>\n",
       "      <td>-1.824352</td>\n",
       "      <td>3.256963</td>\n",
       "      <td>-6.114847</td>\n",
       "      <td>7.117705</td>\n",
       "      <td>-3.914057</td>\n",
       "      <td>-2.118268</td>\n",
       "      <td>-8.542857</td>\n",
       "      <td>2.574036</td>\n",
       "      <td>-4.351186</td>\n",
       "      <td>...</td>\n",
       "      <td>3.109948</td>\n",
       "      <td>1.293072</td>\n",
       "      <td>-0.063146</td>\n",
       "      <td>0.587087</td>\n",
       "      <td>-0.982488</td>\n",
       "      <td>1.330982</td>\n",
       "      <td>4.125036</td>\n",
       "      <td>2.507998</td>\n",
       "      <td>-0.313932</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198676 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "199364  1.413858  0.513670 -0.191584 -0.692890 -0.430233  0.057651 -0.307472   \n",
       "199365 -0.777657 -2.638496 -0.143050 -2.571326  3.740714 -5.433100  2.891171   \n",
       "199366  1.547622  0.684211  0.810322 -3.310242  1.091240  0.304907 -0.992447   \n",
       "199367 -0.371902  0.030242  0.838018 -0.652070  1.421308  1.258755 -0.493169   \n",
       "199368  1.280015 -0.500190  3.091246 -5.385275  5.108693  0.125166 -1.553427   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "398035 -0.752255  0.304369  0.558933 -0.008388  1.543894  0.334196 -0.201913   \n",
       "398036 -0.558355 -1.302583  0.386965 -2.476653  2.749544 -1.787077 -0.932275   \n",
       "398037 -0.719288 -1.178003 -2.011858 -2.353662  2.244191 -2.008679 -0.164926   \n",
       "398038  1.116084  0.617068  1.647715 -3.609284  3.839692  0.920516 -1.180513   \n",
       "398039 -0.128231 -1.824352  3.256963 -6.114847  7.117705 -3.914057 -2.118268   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "199364  0.091250 -0.034340  0.027063  ...  0.179966  0.422524  0.491732   \n",
       "199365  1.319879  0.013499 -2.548130  ...  0.219142  1.712661 -1.774093   \n",
       "199366 -1.147247  0.231530 -1.053749  ...  0.506016  0.048077 -0.204995   \n",
       "199367  0.368652  0.030844 -0.359262  ... -0.443953 -0.956630 -0.371829   \n",
       "199368 -2.454151  1.463718 -4.064389  ...  0.702901 -0.675063  0.032601   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "398035  0.100440  0.184628 -0.702244  ...  0.008703 -0.068580 -0.129247   \n",
       "398036 -2.537207  0.712280 -1.964642  ...  0.974433  0.110299  1.531079   \n",
       "398037 -0.698783  0.273642 -0.725882  ...  1.665281 -0.963772 -2.357683   \n",
       "398038 -0.822104  0.128453 -2.501158  ...  0.322107 -0.580361 -0.230338   \n",
       "398039 -8.542857  2.574036 -4.351186  ...  3.109948  1.293072 -0.063146   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount  \\\n",
       "199364  0.791796 -0.599166 -0.395737  0.050808  0.133889  0.050697   \n",
       "199365 -0.082667 -0.652637  0.890843  3.840468 -3.278482  5.269484   \n",
       "199366 -0.090242  0.900268  1.422340  0.945673  0.518235 -0.342176   \n",
       "199367 -1.521698  0.748432 -0.412022  0.275331  0.321380 -0.341504   \n",
       "199368 -1.892505  0.112759  1.117347  1.293620  0.399456 -0.342403   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "398035 -0.291959  0.617870 -0.027813 -0.023543  0.133395 -0.344205   \n",
       "398036  0.225032 -0.821167 -0.671386  1.890358  0.522632  1.045738   \n",
       "398037 -0.116647  0.440763  1.101008  0.737277  1.597718  5.089672   \n",
       "398038 -0.064846  1.169091  0.406801  1.213158  0.869423 -0.339422   \n",
       "398039  0.587087 -0.982488  1.330982  4.125036  2.507998 -0.313932   \n",
       "\n",
       "        is_original  \n",
       "199364        False  \n",
       "199365        False  \n",
       "199366        False  \n",
       "199367        False  \n",
       "199368        False  \n",
       "...             ...  \n",
       "398035        False  \n",
       "398036        False  \n",
       "398037        False  \n",
       "398038        False  \n",
       "398039        False  \n",
       "\n",
       "[198676 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "is_original = np.arange(len(X_train_smote_df)) < n_original\n",
    "X_train_smote_df[\"is_original\"] = is_original\n",
    "X_train_smote_df[X_train_smote_df['is_original']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caac3059-9c5b-4197-9975-84111945b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators =300,\n",
    "    max_depth = None,\n",
    "    min_samples_leaf =5,\n",
    "    min_samples_split =10,\n",
    "    n_jobs =-1,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state =50,\n",
    "    class_weight = None\n",
    ")\n",
    "rf.fit(X_train_smote, y_train_smote)\n",
    "y_proba_rf = rf.predict_proba(X_test_scaled)[:,1]\n",
    "y_pred_rf = (y_proba_rf >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "143eb5ba-dc05-4eb7-b0da-a52d14be36f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.9754\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC\", roc_auc_score(y_test,y_proba_rf).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf75a65b-eea9-46b8-83dd-7d64406ee4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9997    0.9997     85295\n",
      "           1     0.8333    0.8446    0.8389       148\n",
      "\n",
      "    accuracy                         0.9994     85443\n",
      "   macro avg     0.9165    0.9222    0.9193     85443\n",
      "weighted avg     0.9994    0.9994    0.9994     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25d2407b-c980-40b6-a615-d046851ca2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85270    25]\n",
      " [   23   125]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3159b66d-d5d7-4bf2-a89a-543437d23cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V14       0.151033\n",
      "V10       0.123341\n",
      "V4        0.105139\n",
      "V12       0.102750\n",
      "V17       0.098602\n",
      "V11       0.081278\n",
      "V16       0.047652\n",
      "V3        0.046259\n",
      "V7        0.032339\n",
      "V2        0.024397\n",
      "V9        0.018299\n",
      "V18       0.018282\n",
      "V21       0.015414\n",
      "V8        0.014337\n",
      "V19       0.012998\n",
      "V5        0.011187\n",
      "V1        0.011105\n",
      "Amount    0.010426\n",
      "V13       0.009036\n",
      "V6        0.008949\n",
      "V15       0.007266\n",
      "V26       0.006679\n",
      "Time      0.006615\n",
      "V20       0.006378\n",
      "V28       0.005951\n",
      "V27       0.005604\n",
      "V23       0.005421\n",
      "V25       0.005197\n",
      "V24       0.004110\n",
      "V22       0.003956\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feat_imp = pd.Series(importances,index =X_train.columns).sort_values(ascending=False)\n",
    "print(feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c5438-c02a-4413-8444-8f2f7d7a9312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters tuning\n",
    "# As SMOTE will be computationally high we will use class weights\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold \n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2cde49-ef2f-46f8-9745-f8c40328d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits =3, shuffle= True,random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8415206d-cb0a-47e0-aa28-420655b5ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    \"n_estimators\" : [200,300],\n",
    "    \"max_depth\" : [6,14],\n",
    "    \"min_samples_leaf\" :[10,50]\n",
    "}\n",
    "scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "\n",
    "rf = RandomForestClassifier(random_state =50,n_jobs =1,class_weight =\"balanced_subsample\")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator =rf,\n",
    "    param_distributions =param_grid,\n",
    "    n_iter =15,\n",
    "    scoring =scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=1,\n",
    "    verbose=2,\n",
    "    random_state =50,\n",
    "    return_train_score =True\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_scaled,y_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV ROC-AUC (fraud, CV):\", grid.best_score_)\n",
    "best_rf = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d52e893-cf1d-4013-b989-8d550a35fb22",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "While Random Forests offer modeling flexibility, their computational cost on this dataset\n",
    "(especially under cross validation) outweighs the marginal performance gains on local hardware.\n",
    "For this project, logistic regression remains the preferred model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdcbc82-785a-4d08-90ce-56be8517423b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d3f7a-5f8d-4741-8c02-33f53dc10f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
